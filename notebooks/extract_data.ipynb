{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b036aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "import pretty_errors\n",
    "import PyPDF2\n",
    "from unstructured.partition.pdf import partition_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a7c849",
   "metadata": {},
   "source": [
    "The PDF contains several pages with irrelevant or uninformative content. To optimize processing, we will first identify and select only the relevant pages before extracting elements from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b04e6e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from io import BytesIO\n",
    "\n",
    "irrelevant_content_pages = list(range(0, 8)) + list(range(51, 54))\n",
    "\n",
    "with open('../see_report.pdf', 'rb') as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    total_pages = len(reader.pages)\n",
    "    writer = PyPDF2.PdfWriter()\n",
    " \n",
    "    remaining_pages = filter(lambda x: x not in irrelevant_content_pages, range(total_pages))   \n",
    "\n",
    "    for page_num in remaining_pages:\n",
    "        writer.add_page(reader.pages[page_num])\n",
    "    \n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.pdf')\n",
    "    writer.write(temp_file)\n",
    "    temp_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bb6a9b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pdf_elements = partition_pdf(\n",
    "    temp_file.name, \n",
    "    strategy='hi_res',\n",
    "    extract_images_in_pdf=True,\n",
    "    infer_table_structure=True,\n",
    "\n",
    "    extract_image_block_types=[\"Image\"],   \n",
    "    \n",
    "    extract_image_block_to_payload=True,\n",
    "    \n",
    "    max_characters=10000,\n",
    "    new_after_n_chars=6000,\n",
    "    \n",
    "    languages=['eng'],\n",
    ")\n",
    "\n",
    "os.unlink(temp_file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6386cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 741/741 [00:00<00:00, 293177.93it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "from unstructured.documents.elements import Table, Image, NarrativeText, FigureCaption, Formula\n",
    "\n",
    "table_caption_pattern = re.compile(r'^Table \\d+\\.\\d+: ')\n",
    "image_caption_pattern = re.compile(r'^Figure \\d+\\.\\d+: ')\n",
    "\n",
    "texts, tables, images = [], [], []\n",
    "formulas, table_captions, image_captions = [], [], []\n",
    "\n",
    "for element in tqdm(raw_pdf_elements):\n",
    "    text = getattr(element, \"text\", \"\")\n",
    "\n",
    "    if isinstance(element, (FigureCaption, NarrativeText)):\n",
    "        if table_caption_pattern.match(text):\n",
    "            table_captions.append(text)\n",
    "        elif image_caption_pattern.match(text):\n",
    "            image_captions.append(text)\n",
    "        elif isinstance(element, NarrativeText):\n",
    "            texts.append(text)\n",
    "\n",
    "    elif isinstance(element, Table):\n",
    "        tables.append(element.metadata.text_as_html) # Add the table as html for more clarity\n",
    "\n",
    "    elif isinstance(element, Image):\n",
    "        images.append(element)\n",
    "\n",
    "    elif isinstance(element, Formula):\n",
    "        formulas.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9bba5d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Textual Chunks: 168\n",
      "No of Table Elements: 11\n",
      "No of Images: 45\n"
     ]
    }
   ],
   "source": [
    "print(\"No of Textual Chunks:\", len(texts))\n",
    "print(\"No of Table Elements:\", len(tables))\n",
    "print(\"No of Images:\", len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "66dd6092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Table 1: Table 3.1: Questionnaire subsections: Factors affecting software --------------------\n",
      "('<table><tbody><tr><td>Organization environment</td><td>Income policies, '\n",
      " 'development environment, impact of public policy and economic '\n",
      " 'instability.</td><td></td></tr><tr><td></td><td>Requirements stability and '\n",
      " 'flexibility,</td><td></td></tr><tr><td>Users</td><td>top management support, '\n",
      " 'user availability and '\n",
      " 'resistance.</td><td>13</td></tr><tr><td></td><td>experience, cohesion, '\n",
      " 'continuity, and capability Scheduling, outsourcing, '\n",
      " 'reuse,</td><td>18</td></tr><tr><td>Project Management</td><td>technical '\n",
      " 'stability, risk management, use of '\n",
      " 'standards.</td><td>20</td></tr><tr><td>Product</td><td>Reusability and '\n",
      " 'documentation.</td><td>a</td></tr><tr><td>Product complexity</td><td>straint '\n",
      " 'Technical and quality c</td><td>a</td></tr></tbody></table>')\n",
      "\n",
      "\n",
      "\n",
      "-------------------- Table 2: Table 3.6: New dataset features --------------------\n",
      "('<table><thead><tr><th></th><th>the software '\n",
      " 'system</th></tr></thead><tbody></tbody></table>')\n",
      "\n",
      "\n",
      "\n",
      "-------------------- Table 3: Table 3.2: SEERA dataset attributes --------------------\n",
      "('<table><thead><tr><th></th><th>Organization '\n",
      " 'type</th><th></th></tr></thead><tbody><tr><td>General '\n",
      " 'Information</td><td>Role in organization Size of organization Size of IT '\n",
      " 'department Customer organization type</td><td>ProjID Year of project '\n",
      " 'Organization id Actual duration</td></tr><tr><td>Size</td><td>Application '\n",
      " 'domain</td><td>Object points Other sizing '\n",
      " 'method</td></tr><tr><td>Effort</td><td></td><td>Estimated size Estimated '\n",
      " 'effort</td></tr><tr><td>Environment</td><td>Government policy impact '\n",
      " 'Organization management structure clarity</td><td>Actual effort Contract '\n",
      " 'maturity Economic instability impact</td></tr><tr><td></td><td>Developer '\n",
      " 'hiring policy Developer training Top management opinion of previous '\n",
      " 'system</td><td>Developers incentives policy Development team management Top '\n",
      " 'management sup port</td></tr><tr><td>Users</td><td>Clarity of manual system '\n",
      " 'User computer experience Users’ stability Project manager experience '\n",
      " 'Consultant availability</td><td>User resistance Requirement stabili '\n",
      " 'Requirements flexibi Precedentedness Programmers capabi Analysts capability '\n",
      " 'y ity ity</td></tr><tr><td>Developers</td><td>DBMS expert availability '\n",
      " 'Software tool experience Programmers experience in programming language Team '\n",
      " 'selection Income satisfaction</td><td>Team size Dedicated team mem bers '\n",
      " 'Daily working hours Team contracts Team continuity Team '\n",
      " 'cohesion</td></tr><tr><td></td><td>Schedule quality Methodology Programming '\n",
      " 'language used DBMS used</td><td>Development environment Adequacy Tool '\n",
      " 'availability</td></tr></tbody></table>')\n",
      "\n",
      "\n",
      "\n",
      "-------------------- Table 4: Table 3.8: General information about genetic algorithms results --------------------\n",
      "('<table><thead><tr><th>Model</th><th>Duration</th><th>Num</th><th>Generations</th><th>generated</th><th>Max '\n",
      " 'Score</th></tr></thead><tbody><tr><td>Linear Regression</td><td>2 '\n",
      " 'hours</td><td></td><td>&gt; '\n",
      " '10000</td><td></td><td>0.99872</td></tr><tr><td>SVR</td><td>2 '\n",
      " 'hours</td><td></td><td>&gt; '\n",
      " '8000</td><td></td><td>0.99850</td></tr><tr><td>Random Forest</td><td>2 '\n",
      " 'hours</td><td></td><td>&gt; '\n",
      " '120</td><td></td><td>0.88915</td></tr><tr><td>Neural Network</td><td>5 '\n",
      " 'hours</td><td></td><td>7</td><td></td><td></td></tr></tbody></table>')\n",
      "\n",
      "\n",
      "\n",
      "-------------------- Table 5: Table 2.1: General information of analyzed papers --------------------\n",
      "('<table><thead><tr><th></th><th>Title</th><th>Year</th><th>Journal/Conference</th></tr></thead><tbody><tr><td>[PA]</td><td>Software '\n",
      " 'Development Effort Estimation Using Ensemble Machine '\n",
      " 'Learning</td><td>2017</td><td>Int’] Journal of Computing, Communications '\n",
      " 'Instrumentation Engg.</td></tr><tr><td>83]</td><td>Predictive analytics '\n",
      " 'approaches for software effort estimation: A '\n",
      " 'review</td><td>2020</td><td>Indian Journal of Science an '\n",
      " 'Technology</td></tr><tr><td>4</td><td>Comparative Analysis on prediction of '\n",
      " 'Software Effort Estimation Using Machine Learning '\n",
      " 'Techniques</td><td>2020</td><td>SSRN Electronic '\n",
      " 'Journal</td></tr><tr><td>6)</td><td>Software Effort Estimation Using Machine '\n",
      " 'Learning Techniques</td><td>2014</td><td>Indian Software engineering '\n",
      " 'Conference</td></tr><tr><td>{6</td><td>GA-based method for feature selection '\n",
      " 'and parameters optimization for Machine Learning regression applied to '\n",
      " 'software effort estimation</td><td>2010</td><td>Indian Software engineering '\n",
      " 'Conference</td></tr><tr><td>ia}</td><td>Features-level Software Effort '\n",
      " 'Estimation Using Machine Learning algorithms</td><td>2018</td><td>2018 '\n",
      " 'International Conference on Innovation and Intelligence for informatics, '\n",
      " 'Computing, and Technologies</td></tr><tr><td>[3]</td><td>Software Effort '\n",
      " 'Estimation Using Machine Learning methods</td><td>2007</td><td>2007 22nd '\n",
      " 'international symposium on computer and information '\n",
      " 'sciences.</td></tr><tr><td>{9}</td><td>ENNA: Software effort estimation '\n",
      " 'using ensemble of neural networks with associative '\n",
      " 'memory.</td><td>2008</td><td>Proceedings of the 16th ACM SIGSOFT '\n",
      " 'International Syposium of Foundations of Software '\n",
      " 'Engineering.</td></tr><tr><td></td><td>Predicting Software Effort Estimation '\n",
      " 'Using Machine Learning Techniques</td><td>2018</td><td>2018 8th '\n",
      " 'International Conference on Computer Science and Information Technology '\n",
      " '(CSIT).</td></tr><tr><td></td><td>Comparative analysis of Machine Learning '\n",
      " 'and Deep Learning algorithms for Software Effort '\n",
      " 'Estimation</td><td>2021</td><td>Journal of Physics Conferences '\n",
      " 'series.</td></tr><tr><td></td><td>Machine Learning Models for Software Cost '\n",
      " 'Estimation</td><td>2019</td><td>2019 International Conferences on innovation '\n",
      " 'and Intelligence for Informatics, Computing, and '\n",
      " 'Technologies.</td></tr><tr><td>[13]</td><td>Machine Learning Classification '\n",
      " 'to Effort Estimation for embedded Software Development '\n",
      " 'projects.</td><td>2019</td><td>2019 International Conferences on innovation '\n",
      " 'and International Journal of Software '\n",
      " 'Innovation</td></tr><tr><td></td><td>Software Effort Estimation using '\n",
      " 'Machine Learning Techniques with Robust Confidence '\n",
      " 'Intervals.</td><td>2007</td><td>19th IEEE International Conference on Tools '\n",
      " 'with artificial Intelligence</td></tr><tr><td>15</td><td>Estimation of '\n",
      " 'software project effort with Support Vector '\n",
      " 'regression.</td><td>2006</td><td>Neurocomputing</td></tr><tr><td></td><td>Enhanced '\n",
      " 'Software Effort Estimation using Multi Layered Feed Forward Artificial '\n",
      " 'Neural Network Technique.</td><td>2016</td><td>Twelfth International '\n",
      " 'Multi-Conference on Information Processing-2016</td></tr><tr><td></td><td>A '\n",
      " 'Principled Evaluation of Ensembles of Learning Machines for Software Effort '\n",
      " 'Estimation</td><td>2011</td><td>Promise ’11: 7th International Conference on '\n",
      " 'Predictive Models in Software Engineering.</td></tr></tbody></table>')\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "sample = 5  \n",
    "sampled = random.sample(list(zip(tables, table_captions)), min(sample, len(tables)))\n",
    "\n",
    "for i, (table, caption) in enumerate(sampled):\n",
    "    print('-' * 20 + f' Table {i+1}: {caption} ' + '-' * 20)\n",
    "    pprint(str(table))\n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0f1a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter retrieved chunks that only contains page numbers\n",
    "\n",
    "texts = list(filter(lambda x: 'Page' not in x, texts))\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09270017",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, text in enumerate(texts[:10]):\n",
    "    pprint.pp('-'*20 + f'Text {i+1}' + '-'*20)\n",
    "    pprint.pp(text)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25f1511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from IPython.display import Image\n",
    "\n",
    "base64_images = [el.metadata.image_base64 for el in images]\n",
    "\n",
    "# Displaying some images\n",
    "for image in base64_images[:10]:\n",
    "    image_data = base64.b64decode(image)\n",
    "    display(Image(data=image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc6256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in raw_pdf_elements:\n",
    "    if \"unstructured.documents.elements.Text\" in str(type(element)):\n",
    "        print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c897f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size = 1000, chunk_overlap = 100\n",
    ")\n",
    "\n",
    "joined_texts = \" \".join(texts)\n",
    "texts_token = text_splitter.split_text(joined_texts)\n",
    "\n",
    "print(\"No of Text Chunks after Tokenization:\", len(texts_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d580c0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
